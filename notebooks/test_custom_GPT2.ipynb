{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed2aded0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(30000, 256)\n",
       "    (wpe): Embedding(512, 256)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-3): 4 x GPT2Block(\n",
       "        (ln_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=768, nx=256)\n",
       "          (c_proj): Conv1D(nf=256, nx=256)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=1024, nx=256)\n",
       "          (c_proj): Conv1D(nf=256, nx=1024)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=256, out_features=30000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# üß† Step 1: Load Model and Tokenizer\n",
    "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
    "import torch\n",
    "\n",
    "# Load your custom tokenizer and model\n",
    "model_dir = \"gpt2_custom_model\"\n",
    "tokenizer_dir = \"tokenizer_gpt2_custom\"\n",
    "\n",
    "tokenizer = GPT2TokenizerFast.from_pretrained(tokenizer_dir, pad_token=\"<pad>\")\n",
    "model = GPT2LMHeadModel.from_pretrained(model_dir)\n",
    "\n",
    "# Set model to evaluation mode\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9accebbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìù Generated Text:\n",
      "\n",
      "Once upon a time of all, please go on the time and go to the party here.The Washington PostThe House House bill is running on March 30, 2017.The bill will receive. With the Federal House and bill a number. But the Senate will be allowed to make it clear if Congress is on the states that they would have been, according to the Senate Senate.The bill has been under the House, and Senate bill says Congress will not be an likely to be\n"
     ]
    }
   ],
   "source": [
    "# üìù Step 2: Define Prompt and Generate Text\n",
    "\n",
    "prompt = \"Once upon a time\"\n",
    "input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# Generate continuation\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=100,\n",
    "    num_return_sequences=1,\n",
    "    do_sample=True,           # For creative/random outputs\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    temperature=0.9,\n",
    "    pad_token_id=tokenizer.pad_token_id\n",
    ")\n",
    "\n",
    "# Decode and print result\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(\"üìù Generated Text:\\n\")\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0ac9ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best Tv show is it to get a new version.The second episode of the most popular song are the first two.The story is the name of the song. The song is the second and is also the first and its the music film is the music.The film is made the best album.The film is the first film that is on the movie. The film has shown that The film has been released in the book.The song has become the first\n"
     ]
    }
   ],
   "source": [
    "def generate_text(prompt, max_len=100):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors=\"pt\")\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        max_length=max_len,\n",
    "        do_sample=True,\n",
    "        top_k=40,\n",
    "        top_p=0.9,\n",
    "        temperature=0.8,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "# Try it:\n",
    "print(generate_text(\"The best Tv show is \"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
